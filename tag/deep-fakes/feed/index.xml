<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	
	xmlns:georss="http://www.georss.org/georss"
	xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#"
	>

<channel>
	<title>Deep Fakes &#8211; La Tecnòloga</title>
	<atom:link href="/tag/deep-fakes/feed/" rel="self" type="application/rss+xml" />
	<link>/</link>
	<description>La revista tecnològica digital en català</description>
	<lastBuildDate>Sat, 23 May 2020 11:28:39 +0000</lastBuildDate>
	<language>ca</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.8.2</generator>

<image>
	<url>/wp-content/uploads/2019/10/icona_64_fons_trans.png</url>
	<title>Deep Fakes &#8211; La Tecnòloga</title>
	<link>/</link>
	<width>32</width>
	<height>32</height>
</image> 
<site xmlns="com-wordpress:feed-additions:1">177489427</site>	<item>
		<title>Facebook prohibeix els &#8216;deepfakes&#8217;, però permet alguns vídeos manipulats</title>
		<link>/2020/01/08/facebook-prohibeix-els-deepfakes-pero-permet-alguns-videos-manipulats/</link>
					<comments>/2020/01/08/facebook-prohibeix-els-deepfakes-pero-permet-alguns-videos-manipulats/#respond</comments>
		
		<dc:creator><![CDATA[La Tecnòloga]]></dc:creator>
		<pubDate>Wed, 08 Jan 2020 11:38:25 +0000</pubDate>
				<category><![CDATA[Notícies]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Deep Fakes]]></category>
		<category><![CDATA[Facebook]]></category>
		<category><![CDATA[Fake News]]></category>
		<category><![CDATA[Intel·ligència Artificial]]></category>
		<category><![CDATA[Notícies Falses]]></category>
		<guid isPermaLink="false">/?p=633</guid>

					<description><![CDATA[Facebook eliminarà vídeos manipulats amb Intel·ligència Artificial (IA) per distorsionar la realitat, coneguts com a &#8216;deepfakes&#8217;, alguns dels quals són pràcticament indistingibles d&#8217;un vídeo real.&#8230;]]></description>
										<content:encoded><![CDATA[
<p>Facebook eliminarà vídeos manipulats amb Intel·ligència Artificial (IA) per distorsionar la realitat, <a href="/2019/11/13/equipo-e-deepfake-desinformacio/">coneguts com a &#8216;deepfakes&#8217;</a>, alguns dels quals són pràcticament indistingibles d&#8217;un vídeo real. Però&#8230; què són exactament els deepfakes? Tècnicament, són models matemàtics d&#8217;Aprenentatge Automàtic (<em>Machine Learning</em>) que analitzen milers de fotos d&#8217;una persona i aprenen a generar imatges amb la seva cara. Si això es fa per separat amb dues persones i es combinen els dos models, s&#8217;aconsegueix crear un model nou -o sigui, una imatge nova-, que és el deepfake.</p>



<p>D&#8217;aquesta manera, <a rel="noreferrer noopener" aria-label="En un comunicat, la companyia explica que suprimirà o etiquetarà els vídeos fets amb la intenció d'enganyar (opens in a new tab)" href="https://about.fb.com/news/2020/01/enforcing-against-manipulated-media/" target="_blank">Facebook explica en un comunicat que suprimirà o etiquetarà els vídeos fets amb la intenció d&#8217;enganyar</a>; o sigui, aquelles falsificacions que als ulls de qualsevol persona podrien semblar reals, només si han estat fets amb Intel·ligència Artificial. </p>



<p>La companyia, això sí, explica que no implementarà una política de retirada general dels vídeos manipulats marcats com a falsos pels verificadors (<em>fact-checkers</em>). D&#8217;aquesta manera, la nova directriu no s&#8217;aplicarà als vídeos satírics, ni als que només s&#8217;ha canviat l&#8217;ordre dels mots o s&#8217;han suprimit. Així, l&#8217;empresa de Mark Zuckerberg no prohibirà un vídeo com el de la presidenta de la Cambra de Representants dels Estats Units, Nancy Pelosi, que va editar-se (sense fer servir IA) per fer com si anés borratxa, i que va fer-se viral l&#8217;estiu passat.</p>



<figure class="wp-block-embed-youtube wp-block-embed is-type-video is-provider-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<div class="jetpack-video-wrapper"><iframe loading="lazy" title="Doctored Pelosi video highlights the threat of deepfake tech" width="1160" height="653" src="https://www.youtube.com/embed/EfREntgxmDs?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
</div></figure>



<p>Les reaccions al vídeo de Pelosi van ser diverses. Uns, condemnaren Facebook per no prohibir el vídeo. Altres, argumentaren que eliminar-lo assentava un perillós precedent per censurar paròdies polítiques o dissidents.</p>



<p>Sens dubte, els vídeos falsos, editats amb eines a l&#8217;abast de la majoria, constitueixen una amenaça important per als polítics immersos en una cursa electoral, per exemple. Però la pregunta, aleshores, és: qui decideix què és satíric i què és enganyós? On és la línia que separa aquestes dues categories? Cal prohibir els vídeos falsos que mostren, posem per cas, una falsa declaració racista? I això, Facebook, no ho aclareix.</p>



<figure class="wp-block-embed-youtube wp-block-embed is-type-video is-provider-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<div class="jetpack-video-wrapper"><iframe loading="lazy" title="¿Cómo se hace un &#039;deepfake&#039;?" width="1160" height="653" src="https://www.youtube.com/embed/nU0r-5vJUH0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
</div><figcaption>En aquest vídeo, on es mostra com es fa un Deepfake, el secretari general de Vox, Javier Ortega Smith, es transforma en l&#8217;expresident de Ciutadans, Albert Rivera.</figcaption></figure>



<p></p>
]]></content:encoded>
					
					<wfw:commentRss>/2020/01/08/facebook-prohibeix-els-deepfakes-pero-permet-alguns-videos-manipulats/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">633</post-id>	</item>
		<item>
		<title>Intel·ligència Artificial: dilemes ètics del 2020</title>
		<link>/2020/01/03/intelligencia-artificial-els-dilemes-etics-del-2020/</link>
					<comments>/2020/01/03/intelligencia-artificial-els-dilemes-etics-del-2020/#comments</comments>
		
		<dc:creator><![CDATA[Carles Sala i Anna Schnabel]]></dc:creator>
		<pubDate>Fri, 03 Jan 2020 22:23:18 +0000</pubDate>
				<category><![CDATA[Anàlisis]]></category>
		<category><![CDATA[Algorismes]]></category>
		<category><![CDATA[Aprenentatge Profund]]></category>
		<category><![CDATA[Armes autònomes letals]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Deep Fakes]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Intel·ligència Artificial]]></category>
		<category><![CDATA[Lethal autonomous weapon]]></category>
		<category><![CDATA[Military robots]]></category>
		<category><![CDATA[Robots sexuals]]></category>
		<category><![CDATA[Robots soldat]]></category>
		<category><![CDATA[Sexual robots]]></category>
		<guid isPermaLink="false">/?p=568</guid>

					<description><![CDATA[On ens durà enguany, la Intel·ligència Artificial? Ningú en sap del cert la resposta. Però nosaltres tenim clars els dubtes essencials.]]></description>
										<content:encoded><![CDATA[
<p>El meteòric ascens de la Intel·ligència Artificial (IA) durant el 2019 és fruit del seu enorme potencial per a fer-nos, teòricament, l’existència més fàcil. Ja és normal desbloquejar el mòbil amb reconeixement facial, deixar-se guiar per un assistent virtual, veure anuncis personalitzats i escoltar música seguint els consells d&#8217;un algoritme. Acaba la dècada amb la certesa que la nostra vida quotidiana està cada cop més vinculada a l&#8217;aprenentatge de les màquines que, dia a dia, minut a minut, penetra als àmbits més sensibles com les relacions humanes, la salut, la criminalitat, la sexualitat, l&#8217;educació i fins i tot els conflictes armats. On ens durà enguany, la Intel·ligència Artificial? Ningú en sap del cert la resposta, però tenim clars els interrogants.</p>



<p class="has-large-font-size"><strong>La guerra intel·ligent</strong></p>



<p>Fa dos anys,<a href="https://www.theguardian.com/technology/2017/aug/20/elon-musk-killer-robots-experts-outright-ban-lethal-autonomous-weapons-war" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)"> 116 experts en el camp de la Intel·ligència Artificial reclamaven a les Nacions Unides</a> que prohibís l&#8217;ús de <strong>robots soldat</strong>. En una carta advertien que &#8220;les <strong>armes autònomes letals</strong> -o sigui, armes que es disparen soles- fan possible que un conflicte armat es lliuri a una escala més gran que mai, i a intervals de temps tan ràpids que ni els humans podran comprendre&#8221;. La majoria d&#8217;Estats membres han recolzat públicament la prohibició del robot assassí. Tot i així, actualment s&#8217;oposen a vetar-los el<a href="https://www.theguardian.com/science/2019/mar/29/uk-us-russia-opposing-killer-robot-ban-un-ai" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)"> Regne Unit, Israel, Austràlia, Rússia, Corea del Sud o els Estats Units</a>. Dotzenes de<a href="https://www.technologyreview.com/s/614488/why-remote-war-is-bad-war/"> startups privades venen el mite de la guerra intel·ligent</a> i als seus laboratoris s&#8217;inventen noves formes més netes i eficaces de matar. <a href="https://www.ara.cat/internacional/Iran-promet-venjanca-atac-nord-america_0_2373962741.html" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">L’assassinat, aquest divendres, del general iranià Soleimani, amb quatre míssils</a> disparats des d’un dron nord-americà, és una prova més d’aquest procés.&nbsp;</p>



<p>Actualment, el cap d&#8217;Intel·ligència Artificial del Pentàgon, Jack Shanahan, descarta per ara l&#8217;ús de soldats robot. Tot i així, Shanahan vol que l&#8217;IA ocupi un paper central en la lluita bèl·lica i<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.wired.com/story/pentagon-ai-chief-prepares-for-battle/" target="_blank"> l&#8217;Exèrcit ha estat provant el desembre una torreta automatitzada</a>. Mentrestant, la Marina planeja fer servir vaixells no tripulats. Abans d&#8217;assumir el seu càrrec actual, Shahanan dirigia el Projecte Maven, que té com a objectiu desenvolupar drons intel·ligents per detectar les forces enemigues. Segons la revista Wired, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.wired.com/story/pentagon-ai-chief-prepares-for-battle/" target="_blank">el Pentàgon vol gastar-s&#8217;hi al voltant de 4.000 milions de dòlars</a> durant l&#8217;exercici del 2020.</p>



<p>Una cosa queda clara: el govern nord-americà somia amb un exèrcit que utilitzi l&#8217;IA per moure&#8217;s més ràpid al camp de batalla. Però la integració militar de l&#8217;<a rel="noreferrer noopener" aria-label="aprenentatge automàtic (opens in a new tab)" href="https://www.termcat.cat/ca/cercaterm/fitxa/MzcwMTQyMA==" target="_blank">aprenentatge automàtic</a> (<em>Machine Learning</em>) planteja molts dubtes. L&#8217;armament intel·ligent permet eixamplar la distància moral amb una escena bèl·lica, fent menys incòmoda la veritat: que en una guerra s’hi maten persones. </p>



<p class="has-large-font-size"><strong>Robots sexuals</strong></p>



<p>L&#8217;IA també ha entrat per la porta gran del negoci del sexe. Els robots sexuals intel·ligents ja no són ciència ficció i <em>Sex dolls</em>,<a href="https://www.sexdolls.com/with-artificial-intelligence/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)"> una empresa que distribueix nines sexuals intel·ligents</a>, assegura que &#8220;poden calibrar-se fàcilment per fer quasi totes les funcions imaginables&#8221;. A més, explica que també disposen de sensors integrats a les seves mans, als genitals, a la cara i als pits: &#8220;Això permet que el robot pugui sentir quan el toqueu&#8221;. Fins i tot poden suar, gemegar i lubricar-se, segons l&#8217;empresa. A més, les nines poden integrar-se amb la vida quotidiana i, tal com diu la companyia, ofereixen diferents modes: familiar, romàntic o sexy.</p>



<p>La introducció de la tecnologia en les relacions sexuals no és cap novetat, però aquesta vegada el realisme de l&#8217;objecte marca la diferència. Alguns autors fins i tot han plantejat obrir un debat sobre els drets dels robots, com a éssers simbòlics i semblants als humans. Mentrestant, altres defensen que l&#8217;ús dels ninots sexuals intel·ligents no va més enllà d&#8217;una masturbació assistida. Ara bé, els grans problemes arriben quan aquests robots -realistes- perpetuen els estereotips de gènere: potencien els clixés? O -encara pitjor- si els robots s&#8217;assemblen a menors d&#8217;edat: afavoreixen les conductes pedòfiles? Per altra banda, poden contribuir en la cosificació de la dona i, per tant, normalitzar la cultura de la violació. Com influeix allò simbòlic, com el físic d&#8217;un androide, en el món real?</p>



<p class="has-large-font-size"><strong>Generació d&#8217;informació massiva</strong></p>



<p>Durant els darrers anys hi ha hagut una explosió de &#8216;papers&#8217; sobre les Xarxes Generatives Adversàries (també anomenades GAN, segons les sigles de <em>Generative Adversarial Network</em>), que utilitzen l&#8217;<a rel="noreferrer noopener" aria-label="aprenentatge profund (opens in a new tab)" href="https://www.termcat.cat/ca/cercaterm/fitxa/MzcwMTQyMQ==" target="_blank">aprenentatge profund</a> (<em>Deep Learning</em>) per generar imatges, vídeos o àudios hiperrealistes de manera totalment artificial.</p>



<p>Els GAN, en alguns casos, persegueixen fins inofensius, com rejovenir actors de cinema o fer vídeos còmics, però també poden utilitzar-se per a<a href="/2019/11/13/equipo-e-deepfake-desinformacio/"> generar els anomenats <em>Deepfakes</em>,</a> sovint falsificacions malintencionades amb conseqüències preocupants. Artistes com Scarlett Johansson o Katy Perry foren víctimes d&#8217;una sèrie de vídeos pornogràfics falsos que circularen el 2019 per Internet. Però els <em>Deepfakes</em> també podrien servir per implicar algú en un crim que no ha comès, falsejar notícies o manipular l&#8217;opinió pública durant unes eleccions. La polèmica va inundar les xarxes socials quan Obama va deixar anar que “el president Trump és totalment idiota”. Una afirmació que, en realitat, mai va fer.</p>



<figure class="wp-block-embed-youtube wp-block-embed is-type-video is-provider-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<div class="jetpack-video-wrapper"><iframe loading="lazy" title="You Won’t Believe What Obama Says In This Video! &#x1f609;" width="1160" height="653" src="https://www.youtube.com/embed/cQ54GDm1eL0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
</div></figure>



<p>Més enllà de les imatges,<a href="/2019/11/12/openai-allibera-un-generador-intelligent-de-text-que-considerava-massa-perillos/"> els generadors de textos intel·ligents també penetren al mercat</a>. El nivell de sofisticació d&#8217;alguns sistemes és tan gran que <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.digitaltrends.com/cool-tech/japanese-ai-writes-novel-passes-first-round-nationanl-literary-prize/" target="_blank">ja hi ha hagut polèmica per l’ús d’IA en la redacció d’un text presentat a un concurs de literatura</a>. Durant la propera dècada, el futur del periodisme o la redacció de continguts -sobretot les branques menys creatives- es desdibuixa i planteja encara més dubtes.</p>



<p>També és possible crear Deepfakes d&#8217;àudio, que obren horitzons igual d&#8217;inquietants. A través d&#8217;aquest sistema, <a href="https://www.wsj.com/articles/fraudsters-use-ai-to-mimic-ceos-voice-in-unusual-cybercrime-case-11567157402" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">uns estafadors van falsificar la veu d&#8217;un executiu en una trucada de telèfon</a>, aconseguint robar 243.000 dòlars a través d&#8217;un empleat que pensava que rebia instruccions del director de l&#8217;empresa.</p>



<p>Existeix algun sistema fiable per detectar els àudios, vídeos i textos manipulats? La investigació es desplega a les millors universitats i als departaments de recerca de les grans empreses tecnològiques i, tanmateix, els algoritmes de detecció encara no són capaços d&#8217;enxampar les falsificacions de manera immediata. De fet, Facebook va admetre el setembre que <a href="https://ai.facebook.com/blog/deepfake-detection-challenge" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">no era capaç d’identificar els <em>Deepfakes</em> més sofisticats</a> perquè la tecnologia que els produeix millora massa ràpid. En un esforç per combatre la proliferació dels vídeos enganyosos, Facebook, Microsoft i acadèmics de les universitats més punteres, com la d&#8217;Oxford o el MIT, encapçalen el &#8216;<a href="https://venturebeat.com/2019/12/11/facebook-microsoft-and-others-launch-deepfake-detection-challenge/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Deepfake Challenge</a>&#8216; per impulsar la investigació i assegurar el desenvolupament d&#8217;eines de codi obert per la detecció de vídeos sintètics. La companyia de Mark Zukerberg ha destinat més de 10 milions de dòlars per animar a la participació: un senyal del valor de l&#8217;operació.</p>



<p class="has-large-font-size"><strong>Màquines que treballen</strong></p>



<p>El 2020, hi haurà molts àmbits professionals on s’aplicarà l&#8217;IA per primer cop. Els supermercats i les petites botigues comencen a implementar sistemes de predicció de demanda, segons les dades d&#8217;allò que van vendre en determinada data. La Intel·ligència Artificial revolucionarà la logística de les empreses, i ho farà també amb l’educació, la justícia i la medicina.</p>



<p>Els metges s&#8217;estan bolcant en l’aprenentatge automàtic per recolzar la presa de certes decisions. Aquest nou any, ajudarà a molts professionals sanitaris a fer diagnòstics de malalties de manera automàtica. De fet, <a href="https://www.ccma.cat/324/un-sistema-dintelligencia-artificial-millora-la-deteccio-precoc-de-cancer-de-mama/noticia/2976182/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">un programa informàtic ja pot diagnosticar càncer de mama</a> de manera més acurada, eficient i ràpida que un oncòleg a partir d’una mamografia. Algunes teràpies conductuals basades en els <em>smartphones</em> ofereixen la promesa de tractar la depressió, els transtorns alimentaris o l&#8217;abús d&#8217;alguns fàrmacs.</p>



<p>Per altra banda, a les presons catalanes ja fa una dècada que es fan servir algoritmes de presa de decisions per calcular les possibilitats de reincidència dels que surten en llibertat. L&#8217;IA també pot ser utilitzada per predir crims. <a href="https://www.cio.com/article/3401401/can-crime-be-predicted-with-ai-ml.html" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">L&#8217;anomenada &#8216;policia predictiva&#8217; és capaç d&#8217;identificar la data, l&#8217;hora i l&#8217;ubicació en què és més probable que es produeixin certs delictes</a>, per tal que els agents prioritzin aquestes zones i franges temporals. A més, després d&#8217;unes quantes investigacions, els models analítics predictius s&#8217;han perfeccionat molt i de ben segur que seran utilitzats ben aviat a casa nostra. </p>



<p>En l&#8217;àmbit educatiu, algunes facultats estan començant a guardar les dades acadèmiques i no acadèmiques dels estudiants. Sistemes d&#8217;IA són utilitzats per desenvolupar un perfil d&#8217;aprenentatge personalitzat en funció de la capacitat, l&#8217;experiència i la modalitat preferida d&#8217;estudi.<a href="https://www.forbes.com/sites/cognitiveworld/2019/07/12/ai-applications-in-education/#246ec87d62a3"> Els educadors comencen a utilitzar els assistents de veu</a> com l&#8217;Amazon Alexa, Google Home o Apple Siri, que permeten als estudiants interactuar amb material educatiu sense la intervenció del professor. Utilitzar sistemes intel·ligents a escoles i instituts pot incrementar l&#8217;eficiència de moltes institucions educatives i abaixar els costos.</p>



<p class="has-large-font-size"><strong>Biaixos i caixes negres</strong></p>



<p>De moment, però, els sistemes l&#8217;IA no són perfectes i poden cometre errors. Greus. Si un ordinador s&#8217;entrena amb un conjunt de dades suficient i fiable, els resultats poden ser de gran ajuda. Però, en canvi, si s&#8217;alimenta amb informació deficient i esbiaixada, o el sistema no es programa adequadament, els resultats poden conduir a l&#8217;equívoc o, en el pitjor dels casos, a la discriminació i a la desigualtat. Algunes investigacions han destapat que certs sistemes per predir la reincidència dels presos<a href="/2019/11/11/algoritmes-esbiaixats-maquines-que-no-fan-justicia/"> tendien a assignar riscos molt més elevats a les persones de pell fosca que a les de pell blanca</a>. Quin és el problema? Si les dades que alimenten un algoritme contenen una representació esbiaixada de la realitat, les prediccions de l’algoritme predictiu reproduiran el mateix biaix.</p>



<p>Un altre gran escull dels sistemes intel·ligents és allò que es coneix com el problema de la &#8216;caixa negra&#8217;: quan l&#8217;IA pren decisions que cap ésser humà pot explicar. Abans podiem rastrejar les resolucions que una màquina adoptava gràcies a un determinat codi. Però ara, els enfocaments complexos de l&#8217;aprenentatge automàtic poden fer que la presa de decisions automatitzada sigui completament inescrutable. La Intel·ligència Artificial aprèn per sí mateixa i genera respostes i decisions que l&#8217;intel·lecte humà mai podrà concebre, a velocitats fora del nostre abast.</p>



<p>El 2015, un grup de recerca d&#8217;un hospital de Nova York va aplicar l&#8217;aprenentatge profund a la seva base de dades (de 700.000 registres de pacients). El sistema va descobrir patrons ocults en les dades que semblaven anticipar sorprenentment bé l&#8217;aparició de trastorns psiquiàtrics com l&#8217;esquizofrènia, que és molt difícil de predir. El coordinador de l&#8217;equip mèdic es pregunta com és possible, i encara no ho sap.</p>



<p>El problema de la caixa negra és més perillós en l&#8217;àmbit de la Defensa, per exemple. Per això, correspon a les administracions públiques buscar assessorament expert independent i ser transparents en les seves polítiques i la presa de decisions, de manera que les comunitats puguin tenir confiança en què la tecnologia no oferirà resultats esbiaixiats o vulnerarà la sobirania dels professionals de carn i ossos.</p>
]]></content:encoded>
					
					<wfw:commentRss>/2020/01/03/intelligencia-artificial-els-dilemes-etics-del-2020/feed/</wfw:commentRss>
			<slash:comments>4</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">568</post-id>	</item>
		<item>
		<title>Deepfakes per riure&#8230; i enganyar</title>
		<link>/2019/11/13/equipo-e-deepfake-desinformacio/</link>
					<comments>/2019/11/13/equipo-e-deepfake-desinformacio/#respond</comments>
		
		<dc:creator><![CDATA[Anna Schnabel]]></dc:creator>
		<pubDate>Tue, 12 Nov 2019 23:21:28 +0000</pubDate>
				<category><![CDATA[Notícies]]></category>
		<category><![CDATA[Aprenentatge Automàtic]]></category>
		<category><![CDATA[Deep Fakes]]></category>
		<category><![CDATA[Fake News]]></category>
		<category><![CDATA[Falsificacions]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Notícies Falses]]></category>
		<guid isPermaLink="false">/?p=349</guid>

					<description><![CDATA[L&#8217;Equip E, amb E d&#8217;Espanya és el títol d&#8217;un vídeo publicat fa 24 hores, però que ja acumula 700.000 reproduccions. Es tracta d&#8217;una paròdia de&#8230;]]></description>
										<content:encoded><![CDATA[
<p><em>L&#8217;Equip E, amb E d&#8217;Espanya</em> és el títol d&#8217;un vídeo publicat fa 24 hores, però que ja acumula 700.000 reproduccions. Es tracta d&#8217;una paròdia de 2:35 minuts que, amb la tecnologia dels Deepfakes, connecta la mítica sèrie &#8216;Equipo A&#8217; amb les principals cares de la política espanyola que han competit a les eleccions de l&#8217;11 de novembre. </p>



<figure class="wp-block-embed-youtube wp-block-embed is-type-video is-provider-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<div class="jetpack-video-wrapper"><iframe loading="lazy" title="EL EQUIPO E, con E de España [DeepFake]" width="1160" height="653" src="https://www.youtube.com/embed/dj5M4s-cdAw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
</div><figcaption>[DeepFake] El Equipo E, con E de España.</figcaption></figure>



<p>Pablo Casado dona vida al coronel Hannibal, Pablo Iglesias es transforma -amb melena inclosa- en Amanda Allen, Pedro Sánchez encarna el tinent Templeton Peck, Santiago Abascal interpreta a B.A. Baracus, mentre Albert Rivera hi apareix com el capità Murdock.  </p>



<p>És el dotzè vídeo del <a rel="noreferrer noopener" aria-label="canal de Youtube 'Face to Fake' (s'obre en una nova pestanya)" href="https://www.youtube.com/channel/UCg9FVKnbCqfX-OuIFVgEZgw/videos" target="_blank">canal de Youtube &#8216;Face to Fake&#8217;</a>, que utilitza la Intel·ligència Artificial per a divertir els espectadors, tal com s&#8217;autodefineixen els creadors. I sembla que ho han aconseguit. Els vídeos manipulats no són novetat, tot i que sorprèn el realisme que guanyen dia a dia. Altres canals de Youtube, com <a rel="noreferrer noopener" aria-label="Ctrl Shift Face (s'obre en una nova pestanya)" href="https://www.youtube.com/channel/UCKpH0CKltc73e4wh0_pgL3g" target="_blank">Ctrl Shift Face</a>, van més enllà i modifiquen la cara dels actors a temps real.</p>



<figure class="wp-block-embed-youtube wp-block-embed is-type-video is-provider-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<div class="jetpack-video-wrapper"><iframe loading="lazy" title="Bill Hader channels Tom Cruise [DeepFake]" width="1160" height="653" src="https://www.youtube.com/embed/VWrhRBb-1Ig?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
</div><figcaption>[DeepFake] L&#8217;actor Bill Hader es transforma en Tom Cruise.</figcaption></figure>



<h5>No tot són rialles</h5>



<p>Més enllà de les sàtires, la mateixa tecnologia dels Deepfakes té usos professionals i Hollywood ja <a rel="noreferrer noopener" aria-label="utilitza la mateixa tecnologia per rejovenir actors (s'obre en una nova pestanya)" href="https://www.lavanguardia.com/tecnologia/20191106/471413348212/cine-series-hbo-inteligencia-artificial-productoras.html" target="_blank">les fa servir per rejovenir actors</a>. Allò cert, però, és que els Deepfakes han emergit de la cara més fosca d&#8217;Internet, on <a rel="noreferrer noopener" aria-label="s'utilitzaven sobretot per a falsificacions pornogràfiques (s'obre en una nova pestanya)" href="https://www.technologyreview.com/f/614485/deepfake-porn-deeptrace-legislation-california-election-disinformation/" target="_blank">s&#8217;utilitzen sobretot per a falsificacions pornogràfiques</a>. A més a més, es fan servir per a falsejar notícies. De fet, els vídeos manipulats han aterrat a les xarxes socials amb més pena que glòria. Facebook i Twitter van bullir quan Obama pronuncià una frase capaç de generar rius de polèmica: &#8220;El president Trump és totalment idiota&#8221;. En realitat, mai ho va dir. </p>



<figure class="wp-block-embed-youtube wp-block-embed is-type-video is-provider-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<div class="jetpack-video-wrapper"><iframe loading="lazy" title="You Won’t Believe What Obama Says In This Video! &#x1f609;" width="1160" height="653" src="https://www.youtube.com/embed/cQ54GDm1eL0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
</div></figure>



<p>Altres personatges famosos com <a rel="noreferrer noopener" aria-label="Donald Trump (s'obre en una nova pestanya)" href="https://www.youtube.com/watch?v=dJJLqXVpVGY" target="_blank">Donald Trump</a> o <a rel="noreferrer noopener" aria-label="l'actriu Scarlett Johansson (s'obre en una nova pestanya)" href="https://www.youtube.com/watch?v=Eongq2cl8-I" target="_blank">l&#8217;actriu Scarlett Johansson</a> han estat blancs d&#8217;imatges manipulades que han aixecat polseguera i s&#8217;han viralitzat tan bon punt s&#8217;han fet públics. Parlem de vídeos que mostren gestos, expressions i moviments que, pel seu realisme, arriben a confondre l&#8217;espectador. I tenen tots els números de convertir-se en la nova gran font de desinformació.</p>



<h5>Com es genera un Deepfake?</h5>



<p>Els Deepfakes es creen mitjançant algoritmes d&#8217;Intel·ligència Artificial que observen i registren patrons de moviment del rostre d&#8217;algú a partir d&#8217;un vídeo real i, després, els recreen utilitzant les faccions de la cara d&#8217;algú altre que han memoritzat prèviament. El terme &#8220;Deep&#8221; fa referència al concepte del &#8220;Deep Learning&#8221; (Aprenentatge Profund, en català), una família d&#8217;algoritmes d&#8217;Aprenentatge Automàtic (Machine Learning, en anglès) que s’inspira en el funcionament del cervell humà. </p>



<p>Existeix algun sistema fiable per detectar els vídeos manipulats? La investigació es desplega a les millors universitats i als departaments de recerca de les grans empreses tecnològiques però, de moment, els algoritmes de detecció no estan tant perfeccionats com per enxampar-los tot d&#8217;una. De fet, Facebook va admetre el setembre que <a rel="noreferrer noopener" aria-label="no era capaç d'identificar els Deep Fake més sofisticats (s'obre en una nova pestanya)" href="https://ai.facebook.com/blog/deepfake-detection-challenge" target="_blank">no era capaç d&#8217;identificar els Deepfakes més sofisticats</a> perquè la tecnologia que els produeix millora massa ràpid. </p>



<figure class="wp-block-embed-youtube wp-block-embed is-type-video is-provider-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<div class="jetpack-video-wrapper"><iframe loading="lazy" title="Taxi Driver starring Al Pacino [DeepFake]" width="1160" height="653" src="https://www.youtube.com/embed/9NkKj0aNB0s?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
</div><figcaption>[DeepFake] Al Pacino substitueix Robert De Niro a Taxi Driver.</figcaption></figure>



<p>En aquest context, hi ha més preguntes que respostes: Com frenar les mentides, si corren més que les veritats? Fins a quin punt poden arribar a perfeccionar-se els Deepfakes? Què passarà quan es viralitzi la imatge d&#8217;un líder polític cometent un acte deshonest, però no es pugui saber si és real o fals? Quins continguts es viralitzaran quan tothom pugui fer vídeos falsos des de qualsevol ordinador? </p>



<p>De moment, la legislació no és clara sobre els Deepfakes, tot i que un grapat d&#8217;Estats ja han pres partit. Fa menys d&#8217;una setmana que <a rel="noreferrer noopener" aria-label="Califòrnia ha il·legalitzat la creació i la distribució (s'obre en una nova pestanya)" href="https://www.theguardian.com/us-news/2019/oct/07/california-makes-deepfake-videos-illegal-but-law-may-be-hard-to-enforce" target="_blank">Califòrnia ha il·legalitzat la creació i la distribució</a> de Deepfakes amb l&#8217;argument de protegir els votants de la desinformació.</p>
]]></content:encoded>
					
					<wfw:commentRss>/2019/11/13/equipo-e-deepfake-desinformacio/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">349</post-id>	</item>
	</channel>
</rss>
